{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SBzW6UeJq2e"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sample document\n",
        "document = \"Natural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages.\""
      ],
      "metadata": {
        "id": "n2Hm52agLCPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokens = word_tokenize(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPe7bwsxLHHx",
        "outputId": "2d21e25c-94f2-46a5-c8fa-5350515f594c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# POS tagging\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "  \n",
        "pos = pos_tag(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qtxlMRjLPU7",
        "outputId": "71c993c2-0cc8-45c2-e603-f1c11a0cefad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop words removal\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0qN-SQOLbQ2",
        "outputId": "2e639856-3b78-48aa-abfe-0ee38d0385ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]"
      ],
      "metadata": {
        "id": "24YKEXrxLs1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnNtvMkOL6oz",
        "outputId": "46e3ce92-e853-469e-e228-6bedee1f9611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the results\n",
        "print(\"Original Document: \\n\", document)\n",
        "print(\"\\nTokenization: \\n\", tokens)\n",
        "print(\"\\nPOS Tagging: \\n\", pos)\n",
        "print(\"\\nStop Words Removal: \\n\", filtered_tokens)\n",
        "print(\"\\nStemming: \\n\", stemmed_tokens)\n",
        "print(\"\\nLemmatization: \\n\", lemmatized_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAobvUfTMAmJ",
        "outputId": "fdec4e11-cf7a-44f1-e794-94f57280ba45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Document: \n",
            " Natural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages.\n",
            "\n",
            "Tokenization: \n",
            " ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'computer', 'science', ',', 'artificial', 'intelligence', ',', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', '.']\n",
            "\n",
            "POS Tagging: \n",
            " [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('field', 'NN'), ('of', 'IN'), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('artificial', 'JJ'), ('intelligence', 'NN'), (',', ','), ('and', 'CC'), ('computational', 'JJ'), ('linguistics', 'NNS'), ('concerned', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('interactions', 'NNS'), ('between', 'IN'), ('computers', 'NNS'), ('and', 'CC'), ('human', 'JJ'), ('(', '('), ('natural', 'JJ'), (')', ')'), ('languages', 'NNS'), ('.', '.')]\n",
            "\n",
            "Stop Words Removal: \n",
            " ['Natural', 'language', 'processing', '(', 'NLP', ')', 'field', 'computer', 'science', ',', 'artificial', 'intelligence', ',', 'computational', 'linguistics', 'concerned', 'interactions', 'computers', 'human', '(', 'natural', ')', 'languages', '.']\n",
            "\n",
            "Stemming: \n",
            " ['natur', 'languag', 'process', '(', 'nlp', ')', 'field', 'comput', 'scienc', ',', 'artifici', 'intellig', ',', 'comput', 'linguist', 'concern', 'interact', 'comput', 'human', '(', 'natur', ')', 'languag', '.']\n",
            "\n",
            "Lemmatization: \n",
            " ['Natural', 'language', 'processing', '(', 'NLP', ')', 'field', 'computer', 'science', ',', 'artificial', 'intelligence', ',', 'computational', 'linguistics', 'concerned', 'interaction', 'computer', 'human', '(', 'natural', ')', 'language', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "pTnyTN3fMPUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a TfidfVectorizer object\n",
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "OJ4kTKwzMKOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the vectorizer to the document\n",
        "vector = vectorizer.fit_transform([document])"
      ],
      "metadata": {
        "id": "3tV3pIrXNjiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the feature names and tf-idf scores\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "tfidf_scores = vector.toarray()[0]"
      ],
      "metadata": {
        "id": "d84mcFOkNqOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the feature names and tf-idf scores\n",
        "print(\"Term Frequency-Inverse Document Frequency (TF-IDF):\")\n",
        "for i in range(len(feature_names)):\n",
        "    print(feature_names[i], \":\", tfidf_scores[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqHIq4u_Ns-p",
        "outputId": "d393184a-3cd4-4110-9940-5d1a5796ece8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Term Frequency-Inverse Document Frequency (TF-IDF):\n",
            "and : 0.3779644730092272\n",
            "artificial : 0.1889822365046136\n",
            "between : 0.1889822365046136\n",
            "computational : 0.1889822365046136\n",
            "computer : 0.1889822365046136\n",
            "computers : 0.1889822365046136\n",
            "concerned : 0.1889822365046136\n",
            "field : 0.1889822365046136\n",
            "human : 0.1889822365046136\n",
            "intelligence : 0.1889822365046136\n",
            "interactions : 0.1889822365046136\n",
            "is : 0.1889822365046136\n",
            "language : 0.1889822365046136\n",
            "languages : 0.1889822365046136\n",
            "linguistics : 0.1889822365046136\n",
            "natural : 0.3779644730092272\n",
            "nlp : 0.1889822365046136\n",
            "of : 0.1889822365046136\n",
            "processing : 0.1889822365046136\n",
            "science : 0.1889822365046136\n",
            "the : 0.1889822365046136\n",
            "with : 0.1889822365046136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9C4eL4R5O09u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}